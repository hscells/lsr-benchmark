{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22925697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/maik/.tira/extracted_runs/lsr-benchmark/trec-18-web-20251008-test/lightning-ir/2025-10-08-22-39-15/output')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tira.rest_api_client import Client\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "tira = Client()\n",
    "tira.get_run_output(f'lsr-benchmark/lightning-ir/naver-splade-v3-lexical', \"trec-18-web-20251008-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee2ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def du(path):\n",
    "    import subprocess\n",
    "    return subprocess.check_output(['du','-s', path]).split()[0].decode('utf-8')\n",
    "\n",
    "def ds_stats(path):\n",
    "    queries = 0\n",
    "    docs = 0\n",
    "    with gzip.open(path / 'corpus.jsonl.gz', 'rt') as f:\n",
    "        for l in f:\n",
    "            docs += 1\n",
    "    with open(path / 'queries.jsonl', 'r') as f:\n",
    "        for l in f:\n",
    "            queries += 1\n",
    "    return {\"docs_count\": docs, \"queries_count\": queries}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3967835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "trec-robust-2004-fold-5-20250926-test: 100%|██████████| 13/13 [00:02<00:00,  5.93it/s]\n",
      "trec-robust-2004-fold-4-20250926-test: 100%|██████████| 13/13 [00:01<00:00,  6.55it/s]\n",
      "trec-robust-2004-fold-3-20250926-test: 100%|██████████| 13/13 [00:02<00:00,  6.42it/s]\n",
      "trec-robust-2004-fold-2-20250926-test: 100%|██████████| 13/13 [00:02<00:00,  5.80it/s]\n",
      "trec-robust-2004-fold-1-20250927-test: 100%|██████████| 13/13 [00:07<00:00,  1.79it/s]\n",
      "trec-33-rag-20250926_1-training: 100%|██████████| 13/13 [00:01<00:00,  6.64it/s]\n",
      "trec-29-deep-learning-passages-20250926-training: 100%|██████████| 13/13 [00:01<00:00,  6.70it/s]\n",
      "trec-28-misinfo-20251008_1-test: 100%|██████████| 13/13 [00:03<00:00,  3.94it/s]\n",
      "trec-28-deep-learning-passages-20250926-training: 100%|██████████| 13/13 [00:02<00:00,  5.91it/s]\n",
      "trec-23-web-20251008-test: 100%|██████████| 13/13 [00:02<00:00,  6.25it/s]\n",
      "trec-22-web-20251008-test: 100%|██████████| 13/13 [00:02<00:00,  4.97it/s]\n",
      "trec-21-web-20251008-test: 100%|██████████| 13/13 [00:01<00:00,  6.59it/s]\n",
      "trec-20-web-20251008-test: 100%|██████████| 13/13 [00:02<00:00,  6.49it/s]\n",
      "trec-19-web-20251008-test: 100%|██████████| 13/13 [00:02<00:00,  4.98it/s]\n",
      "trec-18-web-20251008-test: 100%|██████████| 13/13 [00:01<00:00,  6.85it/s]\n",
      "tiny-example-20251002_0-training: 100%|██████████| 13/13 [00:01<00:00,  6.62it/s]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS = [\"naver-splade-v3\", \"webis-splade\", \"naver-splade-v3-distilbert\", \"naver-splade_v2_distil\", \n",
    "              \"naver-splade-v3-doc\", \"castorini-unicoil-noexp-msmarco-passage\", \"opensearch-project-opensearch-neural-sparse-encoding-doc-v2-mini\",\n",
    "              \"opensearch-project-opensearch-neural-sparse-encoding-doc-v3-distill\", \"naver-splade-v3-lexical\",\n",
    "              \"opensearch-project-opensearch-neural-sparse-encoding-doc-v2-distill\", \"opensearch-project-opensearch-neural-sparse-encoding-v2-distill\",\n",
    "              \"bge-m3\",\n",
    "                \"bm25\"]\n",
    "\n",
    "DATASETS = [\"trec-robust-2004-fold-5-20250926-test\", \"trec-robust-2004-fold-4-20250926-test\", \"trec-robust-2004-fold-3-20250926-test\", \n",
    "            \"trec-robust-2004-fold-2-20250926-test\", \"trec-robust-2004-fold-1-20250927-test\", \"trec-33-rag-20250926_1-training\", \n",
    "            \"trec-29-deep-learning-passages-20250926-training\", \"trec-28-misinfo-20251008_1-test\", \n",
    "            \"trec-28-deep-learning-passages-20250926-training\", \"trec-23-web-20251008-test\",\n",
    "            \"trec-22-web-20251008-test\", \"trec-21-web-20251008-test\", \"trec-20-web-20251008-test\",\n",
    "            \"trec-19-web-20251008-test\", \"trec-18-web-20251008-test\", \n",
    "            \"tiny-example-20251002_0-training\"\n",
    "             ]\n",
    "SIZES = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    embedding_sizes = {}\n",
    "    for embedding in tqdm(EMBEDDINGS, dataset):\n",
    "        embedding_sizes[embedding] = du(tira.get_run_output(f'lsr-benchmark/lightning-ir/{embedding}', dataset))\n",
    "    SIZES[dataset] = {\n",
    "        'dataset-size': du(tira.download_dataset(task='lsr-benchmark', dataset=dataset)),\n",
    "        'dataset_stats': ds_stats(tira.download_dataset(task='lsr-benchmark', dataset=dataset)),\n",
    "        \"embedding-sizes\": embedding_sizes}\n",
    "\n",
    "with open('../lsr_benchmark/datasets/overview.json', 'w') as f:\n",
    "    f.write(json.dumps(SIZES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485a91c",
   "metadata": {},
   "source": [
    "# Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fc7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_IDS = {\n",
    "    \"trec-robust-2004\": \"Disks~4/5\",\n",
    "    \"trec-33-rag\": \"MS~MARCO$_{2.1}$\",\n",
    "    \"deep-learning-passages\": \"MS~MARCO\",\n",
    "    \"misinfo\": \"ClueWeb12\",\n",
    "    \"trec-23-web\": \"ClueWeb12\",\n",
    "    \"trec-22-web\": \"ClueWeb12\",\n",
    "    \"trec-21-web\": \"ClueWeb09\",\n",
    "    \"trec-20-web\": \"ClueWeb09\",\n",
    "    \"trec-19-web\": \"ClueWeb09\",\n",
    "    \"trec-18-web\": \"ClueWeb09\",\n",
    "}\n",
    "\n",
    "def dataset_id(m):\n",
    "    ret = set()\n",
    "    for k,v in DATASET_IDS.items():\n",
    "        if k in m:\n",
    "            ret.add(v)\n",
    "    assert len(ret) == 1, f\"{m}, {ret}\"\n",
    "    return list(ret)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6329ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS_FOR_TABLE = {}\n",
    "all_stats = json.loads(open('../lsr_benchmark/datasets/overview.json', 'r').read())\n",
    "\n",
    "ALL_EMBEDDINGS = []\n",
    "\n",
    "for k in all_stats:\n",
    "    if \"tiny-example\" in k:\n",
    "        continue\n",
    "    d = dataset_id(k)\n",
    "    if d not in STATS_FOR_TABLE:\n",
    "        STATS_FOR_TABLE[d] = {'docs_count': 0, 'queries_count': 0, \"embedding-sizes\": []}\n",
    "    STATS_FOR_TABLE[d][\"docs_count\"] += all_stats[k][\"dataset_stats\"][\"docs_count\"]\n",
    "    STATS_FOR_TABLE[d][\"queries_count\"] += all_stats[k][\"dataset_stats\"][\"queries_count\"]\n",
    "    STATS_FOR_TABLE[d][\"embedding-sizes\"] += [int(v) for v in all_stats[k]['embedding-sizes'].values()]\n",
    "    ALL_EMBEDDINGS += [int(v) for v in all_stats[k]['embedding-sizes'].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99564bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ClueWeb09 & Web~\\cite{clarke:2009,clarke:2010,clarke:2011,clarke:2012} & 198 & \\phantom{0}84\\,366 & 315095 & 117.9\\,MB & 5.1\\,GB \\\\\n",
      "\n",
      "ClueWeb12 & Web/Dec.~\\cite{abualsaud:2019,thompson:2013,thompson:2014} & 150 & \\phantom{0}51\\,765 & 225636 & 116.0\\,MB & 3.7\\,GB \\\\\n",
      "\n",
      "Disks~4/5 & Robust04~\\cite{voorhees:2004} & 249 & 311\\,410 & 285756 & 106.4\\,MB & 5.7\\,GB \\\\\n",
      "\n",
      "MS~MARCO & DL~19/20~\\cite{craswell:2020,craswell:2019} & 97 & \\phantom{0}20\\,646 & 81737 & 40.1\\,MB & 0.9\\,GB \\\\\n",
      "\n",
      "MS~MARCO$_{2.1}$ & RAG~24~\\cite{upadhyay:2025} & 89 & \\phantom{0}20\\,429 & 116694 & 170.0\\,MB & 1.8\\,GB \\\\\n",
      "\n",
      "All & 106.8\\,MB & 17.2\\,GB\n"
     ]
    }
   ],
   "source": [
    "JUDGMENTS = {\n",
    "    \"ClueWeb09\": \"\\\\phantom{0}84\\\\,366\",\n",
    "    \"ClueWeb12\": \"\\\\phantom{0}51\\\\,765\",\n",
    "    \"Disks~4/5\": \"311\\\\,410\",\n",
    "    \"MS~MARCO\": \"\\\\phantom{0}20\\\\,646\",\n",
    "    \"MS~MARCO$_{2.1}$\": \"\\\\phantom{0}20\\\\,429\"\n",
    "}\n",
    "\n",
    "def line(c):\n",
    "    emb_avg = sum(STATS_FOR_TABLE[c][\"embedding-sizes\"])/(len(STATS_FOR_TABLE[c][\"embedding-sizes\"])*1024)\n",
    "    emb_all = sum(STATS_FOR_TABLE[c][\"embedding-sizes\"])/(1024*1024)\n",
    "    ret = [STATS_FOR_TABLE[c][\"queries_count\"], JUDGMENTS[c], STATS_FOR_TABLE[c][\"docs_count\"], \"{:.1f}\".format(emb_avg) + \"\\,MB\", \"{:.1f}\".format(emb_all) + \"\\,GB\"]\n",
    "    return \" & \".join([str(i) for i in ret])\n",
    "\n",
    "print(\"\"\"\n",
    "ClueWeb09 & Web~\\\\cite{clarke:2009,clarke:2010,clarke:2011,clarke:2012} & \"\"\" + line(\"ClueWeb09\") +  \"\"\" \\\\\\\\\n",
    "\n",
    "ClueWeb12 & Web/Dec.~\\\\cite{abualsaud:2019,thompson:2013,thompson:2014} & \"\"\" + line(\"ClueWeb12\") +  \"\"\" \\\\\\\\\n",
    "\n",
    "Disks~4/5 & Robust04~\\\\cite{voorhees:2004} & \"\"\" + line(\"Disks~4/5\") +  \"\"\" \\\\\\\\\n",
    "\n",
    "MS~MARCO & DL~19/20~\\\\cite{craswell:2020,craswell:2019} & \"\"\" + line(\"MS~MARCO\") +  \"\"\" \\\\\\\\\n",
    "\n",
    "MS~MARCO$_{2.1}$ & RAG~24~\\\\cite{upadhyay:2025} & \"\"\" + line(\"MS~MARCO$_{2.1}$\") +  \"\"\" \\\\\\\\\n",
    "\"\"\")\n",
    "print(\"All & \" + \"{:.1f}\".format(sum(ALL_EMBEDDINGS)/(len(ALL_EMBEDDINGS)*1024)) +  \"\\,MB\" + \" & \" \"{:.1f}\".format(sum(ALL_EMBEDDINGS)/(1024*1024)) +  \"\\,GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
